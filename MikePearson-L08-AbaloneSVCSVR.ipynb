{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 8 Assignment - Abalone Age Determination\n",
    "\n",
    "## Author - Mike Pearson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "Age of abalone is determined by cutting the shell through the cone, staining it, and counting the number of rings through a microscope. Other measurements, which are easier to obtain, could be used to predict the age. According to the data provider, original data examples with missing values were removed (the majority having the predicted value missing), and the ranges of the continuous values have been scaled (by dividing by 200) for use with machine learning algorithms such as SVMs and ANNs.\n",
    "\n",
    "The target field is “Rings”. Since the output is continuous the solution can be handled by a Support Vector Regression or it can be changed to a binary Support Vector Classification by assigning examples that are younger than 11 years old to class: ‘0’ and those that are older (class: ‘1’).\n",
    "\n",
    "Predict the age using the following attributes:\n",
    "* Sex / nominal / -- / M, F, and I (infant)\n",
    "* Length / continuous / mm / Longest shell measurement\n",
    "* Diameter / continuous / mm / perpendicular to length\n",
    "* Height / continuous / mm / with meat in shell\n",
    "* Whole weight / continuous / grams / whole abalone\n",
    "* Shucked weight / continuous / grams / weight of meat\n",
    "* Viscera weight / continuous / grams / gut weight (after bleeding)\n",
    "* Shell weight / continuous / grams / after being dried\n",
    "\n",
    "See [UCI's Abalone Data set](https://archive.ics.uci.edu/ml/datasets/abalone) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "Use the provided abalone.csv file, build an experiment using support vector machine classifier and regression. Complete the following tasks and answer the questions:\n",
    "\n",
    "1. Convert the continuous output value from continuous to binary (0,1) and build an SVC\n",
    "2. Using your best guess for hyperparameters and kernel, what is the percentage of correctly classified results?\n",
    "3. Test different kernels and hyperparameters or consider using `sklearn.model_selection.SearchGridCV`. Which kernel performed best with what settings?\n",
    "4. Show recall, precision and f-measure for the best model\n",
    "5. Using the original data, with rings as a continuous variable, create an SVR model\n",
    "6. Report on the predicted variance and the mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set contains 4177 rows and 9 columns.\n",
    "URL = \"https://library.startlearninglabs.uw.edu/DATASCI420/Datasets/abalone.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sex  Length  Diameter  Height  Whole Weight  Shucked Weight  Viscera Weight  \\\n",
      "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "\n",
      "   Shell Weight  Rings  \n",
      "0         0.150     15  \n",
      "1         0.070      7  \n",
      "2         0.210      9  \n",
      "3         0.155     10  \n",
      "4         0.055      7  \n",
      "Sex                object\n",
      "Length            float64\n",
      "Diameter          float64\n",
      "Height            float64\n",
      "Whole Weight      float64\n",
      "Shucked Weight    float64\n",
      "Viscera Weight    float64\n",
      "Shell Weight      float64\n",
      "Rings               int64\n",
      "dtype: object\n",
      "            Length     Diameter       Height  Whole Weight  Shucked Weight  \\\n",
      "count  4177.000000  4177.000000  4177.000000   4177.000000     4177.000000   \n",
      "mean      0.523992     0.407881     0.139516      0.828742        0.359367   \n",
      "std       0.120093     0.099240     0.041827      0.490389        0.221963   \n",
      "min       0.075000     0.055000     0.000000      0.002000        0.001000   \n",
      "25%       0.450000     0.350000     0.115000      0.441500        0.186000   \n",
      "50%       0.545000     0.425000     0.140000      0.799500        0.336000   \n",
      "75%       0.615000     0.480000     0.165000      1.153000        0.502000   \n",
      "max       0.815000     0.650000     1.130000      2.825500        1.488000   \n",
      "\n",
      "       Viscera Weight  Shell Weight        Rings  \n",
      "count     4177.000000   4177.000000  4177.000000  \n",
      "mean         0.180594      0.238831     9.933684  \n",
      "std          0.109614      0.139203     3.224169  \n",
      "min          0.000500      0.001500     1.000000  \n",
      "25%          0.093500      0.130000     8.000000  \n",
      "50%          0.171000      0.234000     9.000000  \n",
      "75%          0.253000      0.329000    11.000000  \n",
      "max          0.760000      1.005000    29.000000  \n"
     ]
    }
   ],
   "source": [
    "## import the data\n",
    "\n",
    "abalone = pd.read_csv(URL)\n",
    "print(abalone.head())\n",
    "print(abalone.dtypes)\n",
    "print(abalone.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now convert the catagorical variables to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Length  Diameter  Height  Whole Weight  Shucked Weight  Viscera Weight  \\\n",
      "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "\n",
      "   Shell Weight  Rings  Sex_F  Sex_I  Sex_M  \n",
      "0         0.150     15      0      0      1  \n",
      "1         0.070      7      0      0      1  \n",
      "2         0.210      9      1      0      0  \n",
      "3         0.155     10      0      0      1  \n",
      "4         0.055      7      0      1      0  \n"
     ]
    }
   ],
   "source": [
    "catz = [\"Sex\"]\n",
    "wide_abalone = pd.get_dummies(abalone, columns = catz)\n",
    "print(wide_abalone.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's min-max normalize all the features\n",
    "I know that the data has been scaled, but I would like to normalize before continuing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Length     Diameter       Height  Whole Weight  Shucked Weight  \\\n",
      "count  4177.000000  4177.000000  4177.000000   4177.000000     4177.000000   \n",
      "mean      0.523992     0.407881     0.139516      0.828742        0.359367   \n",
      "std       0.120093     0.099240     0.041827      0.490389        0.221963   \n",
      "min       0.075000     0.055000     0.000000      0.002000        0.001000   \n",
      "25%       0.450000     0.350000     0.115000      0.441500        0.186000   \n",
      "50%       0.545000     0.425000     0.140000      0.799500        0.336000   \n",
      "75%       0.615000     0.480000     0.165000      1.153000        0.502000   \n",
      "max       0.815000     0.650000     1.130000      2.825500        1.488000   \n",
      "\n",
      "       Viscera Weight  Shell Weight        Rings        Sex_F        Sex_I  \\\n",
      "count     4177.000000   4177.000000  4177.000000  4177.000000  4177.000000   \n",
      "mean         0.180594      0.238831     9.933684     0.312904     0.321283   \n",
      "std          0.109614      0.139203     3.224169     0.463731     0.467025   \n",
      "min          0.000500      0.001500     1.000000     0.000000     0.000000   \n",
      "25%          0.093500      0.130000     8.000000     0.000000     0.000000   \n",
      "50%          0.171000      0.234000     9.000000     0.000000     0.000000   \n",
      "75%          0.253000      0.329000    11.000000     1.000000     1.000000   \n",
      "max          0.760000      1.005000    29.000000     1.000000     1.000000   \n",
      "\n",
      "             Sex_M  normed length  normed diameter  normed height  \\\n",
      "count  4177.000000    4177.000000      4177.000000    4177.000000   \n",
      "mean      0.365813       0.606746         0.593078       0.123466   \n",
      "std       0.481715       0.162288         0.166790       0.037015   \n",
      "min       0.000000       0.000000         0.000000       0.000000   \n",
      "25%       0.000000       0.506757         0.495798       0.101770   \n",
      "50%       0.000000       0.635135         0.621849       0.123894   \n",
      "75%       1.000000       0.729730         0.714286       0.146018   \n",
      "max       1.000000       1.000000         1.000000       1.000000   \n",
      "\n",
      "       normed w weight  normed s weight  normed v weight  normed shell weight  \n",
      "count      4177.000000      4177.000000      4177.000000          4177.000000  \n",
      "mean          0.292808         0.241000         0.237121             0.236503  \n",
      "std           0.173681         0.149269         0.144324             0.138717  \n",
      "min           0.000000         0.000000         0.000000             0.000000  \n",
      "25%           0.155658         0.124412         0.122449             0.128052  \n",
      "50%           0.282451         0.225286         0.224490             0.231689  \n",
      "75%           0.407650         0.336920         0.332456             0.326358  \n",
      "max           1.000000         1.000000         1.000000             1.000000  \n"
     ]
    }
   ],
   "source": [
    "## normalize the length\n",
    "min_len = np.min(wide_abalone['Length'])\n",
    "max_len = np.max(wide_abalone['Length'])\n",
    "range_len = max_len - min_len\n",
    "wide_abalone['normed length']= (wide_abalone['Length'] - min_len)/range_len\n",
    "\n",
    "## normalize the Diameter\n",
    "min_d = np.min(wide_abalone['Diameter'])\n",
    "max_d = np.max(wide_abalone['Diameter'])\n",
    "range_d = max_d - min_d\n",
    "wide_abalone['normed diameter']= (wide_abalone['Diameter'] - min_d)/range_d\n",
    "\n",
    "## normalize the height\n",
    "min_hei = np.min(wide_abalone['Height'])\n",
    "max_hei = np.max(wide_abalone['Height'])\n",
    "range_hei = max_hei - min_hei\n",
    "wide_abalone['normed height']= (wide_abalone['Height'] - min_hei)/range_hei\n",
    "                              \n",
    "## normalize the Whole Weight\n",
    "min_ww = np.min(wide_abalone['Whole Weight'])\n",
    "max_ww = np.max(wide_abalone['Whole Weight'])\n",
    "range_ww = max_ww - min_ww\n",
    "wide_abalone['normed w weight']= (wide_abalone['Whole Weight'] - min_ww)/range_ww\n",
    "\n",
    "## normalize the Shucked Weight\n",
    "                              \n",
    "min_sw = np.min(wide_abalone['Shucked Weight'])\n",
    "max_sw = np.max(wide_abalone['Shucked Weight'])\n",
    "range_sw = max_sw - min_sw\n",
    "wide_abalone['normed s weight']= (wide_abalone['Shucked Weight'] - min_sw)/range_sw\n",
    "\n",
    "## normalize the Viscera Weight\n",
    "                              \n",
    "min_vw = np.min(wide_abalone['Viscera Weight'])\n",
    "max_vw = np.max(wide_abalone['Viscera Weight'])\n",
    "range_vw = max_vw - min_vw\n",
    "wide_abalone['normed v weight']= (wide_abalone['Viscera Weight'] - min_vw)/range_vw\n",
    "\n",
    "## normalize the Shell Weight\n",
    "                              \n",
    "min_shw = np.min(wide_abalone['Shell Weight'])\n",
    "max_shw = np.max(wide_abalone['Shell Weight'])\n",
    "range_shw = max_shw - min_shw\n",
    "wide_abalone['normed shell weight']= (wide_abalone['Shell Weight'] - min_shw)/range_shw\n",
    "\n",
    "\n",
    "\n",
    "print(wide_abalone.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's set the boundary for the rings at more than 11 = 1 and 11 or less = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Length  Diameter  Height  Whole Weight  Shucked Weight  Viscera Weight  \\\n",
      "4172   0.565     0.450   0.165        0.8870          0.3700          0.2390   \n",
      "4173   0.590     0.440   0.135        0.9660          0.4390          0.2145   \n",
      "4174   0.600     0.475   0.205        1.1760          0.5255          0.2875   \n",
      "4175   0.625     0.485   0.150        1.0945          0.5310          0.2610   \n",
      "4176   0.710     0.555   0.195        1.9485          0.9455          0.3765   \n",
      "\n",
      "      Shell Weight  Rings  Sex_F  Sex_I  Sex_M  normed length  \\\n",
      "4172        0.2490     11      1      0      0       0.662162   \n",
      "4173        0.2605     10      0      0      1       0.695946   \n",
      "4174        0.3080      9      0      0      1       0.709459   \n",
      "4175        0.2960     10      1      0      0       0.743243   \n",
      "4176        0.4950     12      0      0      1       0.858108   \n",
      "\n",
      "      normed diameter  normed height  normed w weight  normed s weight  \\\n",
      "4172         0.663866       0.146018         0.313441         0.248151   \n",
      "4173         0.647059       0.119469         0.341420         0.294553   \n",
      "4174         0.705882       0.181416         0.415796         0.352724   \n",
      "4175         0.722689       0.132743         0.386931         0.356422   \n",
      "4176         0.840336       0.172566         0.689393         0.635171   \n",
      "\n",
      "      normed v weight  normed shell weight  binned rings  \n",
      "4172         0.314022             0.246637           1.0  \n",
      "4173         0.281764             0.258097           0.0  \n",
      "4174         0.377880             0.305431           0.0  \n",
      "4175         0.342989             0.293473           0.0  \n",
      "4176         0.495063             0.491779           1.0  \n"
     ]
    }
   ],
   "source": [
    "bob = len(wide_abalone[\"Rings\"])\n",
    "for i in range(bob):\n",
    "    if wide_abalone.loc[i, \"Rings\"] <= 10 :\n",
    "        wide_abalone.loc[i,\"binned rings\"] = 0\n",
    "    else :\n",
    "        wide_abalone.loc[i,\"binned rings\"] = 1\n",
    "\n",
    "print(wide_abalone.tail())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sex_F  Sex_I  Sex_M  normed length  normed diameter  normed height  \\\n",
      "0      0      0      1       0.513514         0.521008       0.084071   \n",
      "1      0      0      1       0.371622         0.352941       0.079646   \n",
      "2      1      0      0       0.614865         0.613445       0.119469   \n",
      "3      0      0      1       0.493243         0.521008       0.110619   \n",
      "4      0      1      0       0.344595         0.336134       0.070796   \n",
      "\n",
      "   normed w weight  normed s weight  normed v weight  \n",
      "0         0.181335         0.150303         0.132324  \n",
      "1         0.079157         0.066241         0.063199  \n",
      "2         0.239065         0.171822         0.185648  \n",
      "3         0.182044         0.144250         0.149440  \n",
      "4         0.071897         0.059516         0.051350  \n",
      "4172    1.0\n",
      "4173    0.0\n",
      "4174    0.0\n",
      "4175    0.0\n",
      "4176    1.0\n",
      "Name: binned rings, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Separate Features from Target\n",
    "X = wide_abalone.iloc[:, 8:17]   # load features into X DF\n",
    "Y = wide_abalone.iloc[:, 18]     # Load target into Y DF\n",
    "print(X.head())\n",
    "print(Y.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's make the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3342    1.0\n",
      "791     0.0\n",
      "1420    1.0\n",
      "729     1.0\n",
      "1186    1.0\n",
      "Name: binned rings, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into a training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=5)\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now to start with some values for the hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = 1000 # penalty parameter of the error term\n",
    "gamma = 0.2 # defines the influence of input vectors on the margins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now do linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mutecypher/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.74      0.84       705\n",
      "         1.0       0.38      0.84      0.52       131\n",
      "\n",
      "    accuracy                           0.76       836\n",
      "   macro avg       0.67      0.79      0.68       836\n",
      "weighted avg       0.87      0.76      0.79       836\n",
      "\n",
      "[[523  21]\n",
      " [182 110]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sbn\n",
    "\n",
    "clf1 = svm.LinearSVC(C=cost).fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(\"LinearSVC\")\n",
    "print(classification_report(clf1.predict(X_test), y_test))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "ax = sbn.heatmap(confusion_matrix(y_test, y_pred),annot = True, fmt = \"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.81      0.85       595\n",
      "         1.0       0.61      0.74      0.67       241\n",
      "\n",
      "    accuracy                           0.79       836\n",
      "   macro avg       0.75      0.78      0.76       836\n",
      "weighted avg       0.81      0.79      0.80       836\n",
      "\n",
      "[[523  21]\n",
      " [182 110]]\n",
      "rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.83      0.86       584\n",
      "         1.0       0.67      0.77      0.72       252\n",
      "\n",
      "    accuracy                           0.82       836\n",
      "   macro avg       0.78      0.80      0.79       836\n",
      "weighted avg       0.83      0.82      0.82       836\n",
      "\n",
      "[[523  21]\n",
      " [182 110]]\n",
      "poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.80      0.85       614\n",
      "         1.0       0.58      0.77      0.66       222\n",
      "\n",
      "    accuracy                           0.79       836\n",
      "   macro avg       0.74      0.78      0.76       836\n",
      "weighted avg       0.82      0.79      0.80       836\n",
      "\n",
      "[[523  21]\n",
      " [182 110]]\n",
      "sigmoid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.74      0.73       531\n",
      "         1.0       0.52      0.50      0.51       305\n",
      "\n",
      "    accuracy                           0.65       836\n",
      "   macro avg       0.62      0.62      0.62       836\n",
      "weighted avg       0.65      0.65      0.65       836\n",
      "\n",
      "[[523  21]\n",
      " [182 110]]\n"
     ]
    }
   ],
   "source": [
    "# Test linear, rbf and poly kernels\n",
    "cost = 1000 # penalty parameter of the error term\n",
    "gamma = 0.2 # defines the influence of input vectors on the margins\n",
    "\n",
    "for k in ('linear', 'rbf', 'poly','sigmoid'):\n",
    "    clf = svm.SVC(gamma=gamma, kernel=k, C=cost, degree = 4).fit(X_train, y_train)\n",
    "    clf.predict(X_test)\n",
    "    print(k)\n",
    "    print(classification_report(clf.predict(X_test), y_test))\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's try grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C is [1.e-04 1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02 1.e+03 1.e+04]\n",
      "gamma range is  [1.e-04 1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02 1.e+03 1.e+04]\n"
     ]
    }
   ],
   "source": [
    "C_range = np.logspace(-4, 4, 9)\n",
    "gamma_range = np.logspace(-4, 4, 9)\n",
    "degree_param = [2,3,4]\n",
    "print(\"C is\", C_range)\n",
    "print(\"gamma range is \", gamma_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try to narrow our parameter search a little more quickly than Gridsearch, with RandomizedSearch\n",
    "\n",
    "### The polynomial kernel seems the most sensitive to gamma - in terms of the time to calculate.\n",
    "\n",
    "Note - this bit of code takes a while to run, I don't know if you (the evaluator) will run this code or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'C': 10000.0, 'gamma': 0.1, 'kernel': 'rbf'} with a score of 0.79 and time is 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "##from sklearn.model_selection import RandomizedSearchCV\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {'kernel': [ 'linear', 'sigmoid', 'rbf'], 'gamma': gamma_range, 'C' : C_range}\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv = cv)\n",
    "##grid = RandomizedSearchCV(SVC(), param_distributions = param_grid, cv=cv)\n",
    "grid.fit(X_train, y_train)\n",
    "print('The best parameters are %s with a score of %0.2f and time is %0.2f'\n",
    "      % (grid.best_params_, grid.best_score_, grid.refit_time_))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the above for some further refinement...  this time using GridSearch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'C': 10000, 'degree': 3, 'gamma': 0.1, 'kernel': 'rbf'} with a score of 0.79 and time is 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "C_range = [9000,10000, 12000]\n",
    "gamma_range = [0.05, 0.08, 0.1, 0.12]\n",
    "degree_range = [3, 4]\n",
    "\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {'kernel': [ 'linear', 'rbf','poly'], 'gamma': gamma_range, 'C' : C_range, 'degree': degree_range}\n",
    "##param_grid = dict(kernelgamma=gamma_range, C=C_range)\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv = cv)\n",
    "grid.fit(X_train, y_train)\n",
    "print('The best parameters are %s with a score of %0.2f and time is %0.2f'\n",
    "      % (grid.best_params_, grid.best_score_, grid.refit_time_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the GridSearch, get the performance data\n",
    "\n",
    "## Now use the hyperparameters to do a fit that gives us all the performance data\n",
    "\n",
    "### Here we have the recall, precision and f1-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.83      0.86       581\n",
      "         1.0       0.66      0.76      0.71       255\n",
      "\n",
      "    accuracy                           0.81       836\n",
      "   macro avg       0.77      0.79      0.78       836\n",
      "weighted avg       0.82      0.81      0.81       836\n",
      "\n",
      "[[523  21]\n",
      " [182 110]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "clf = svm.SVC(gamma=0.1, kernel='rbf', C= 10000).fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "\n",
    "print(classification_report(clf.predict(X_test), y_test))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "ax = sbn.heatmap(confusion_matrix(y_test, y_pred),annot = True, fmt = \"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now use the hyperparameters to do a fit that gives us all the performance data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now for the unscaled data with linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Length  Diameter  Height  Whole Weight  Shucked Weight  Viscera Weight  \\\n",
      "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "\n",
      "   Shell Weight  Rings  Sex_F  Sex_I  Sex_M  normed length  normed diameter  \\\n",
      "0         0.150     15      0      0      1       0.513514         0.521008   \n",
      "1         0.070      7      0      0      1       0.371622         0.352941   \n",
      "2         0.210      9      1      0      0       0.614865         0.613445   \n",
      "3         0.155     10      0      0      1       0.493243         0.521008   \n",
      "4         0.055      7      0      1      0       0.344595         0.336134   \n",
      "\n",
      "   normed height  normed w weight  normed s weight  normed v weight  \\\n",
      "0       0.084071         0.181335         0.150303         0.132324   \n",
      "1       0.079646         0.079157         0.066241         0.063199   \n",
      "2       0.119469         0.239065         0.171822         0.185648   \n",
      "3       0.110619         0.182044         0.144250         0.149440   \n",
      "4       0.070796         0.071897         0.059516         0.051350   \n",
      "\n",
      "   normed shell weight  binned rings  \n",
      "0             0.147982           1.0  \n",
      "1             0.068261           0.0  \n",
      "2             0.207773           0.0  \n",
      "3             0.152965           0.0  \n",
      "4             0.053313           0.0  \n"
     ]
    }
   ],
   "source": [
    "print(wide_abalone.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR \n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "# Get the unscaled data\n",
    "X1 = wide_abalone[['Length', 'Diameter', 'Height',  'Whole Weight','Shucked Weight', 'Viscera Weight','Shell Weight'\n",
    "            ,'Sex_F', 'Sex_I','Sex_M']]\n",
    "# load features into X DF\n",
    "Y1 = wide_abalone[['Rings']]\n",
    "\n",
    "\n",
    "# split into a training and testing set\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, Y1, test_size=0.2, random_state=5)\n",
    "\n",
    "C_range = [200, 225,250]\n",
    "gamma_range = [1e-12, 1e-11, 1e-10, 4e-10]\n",
    "cv = 5\n",
    "\n",
    "param_grid = {'kernel': ['linear', 'rbf'], 'gamma': gamma_range, 'C' : C_range}\n",
    "##param_grid = dict(kernelgamma=gamma_range, C=C_range)\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv = cv, refit = True)\n",
    "grid.fit(X1_train, y1_train.values.ravel())\n",
    "print('The best parameters are %s with a score of %0.2f and time is %0.2f'\n",
    "      % (grid.best_params_, grid.best_score_, grid.refit_time_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now using the above hyperparameters, we get the performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "model = SVR()\n",
    "print(model)\n",
    "SVR(C = 225, gamma = 1e-12 ,kernel='linear') \n",
    "model.fit(X1_train,y1_train.values.ravel())\n",
    "pred_y = model.predict(X1_test)\n",
    "\n",
    "score=model.score(X1_test,y1_test)\n",
    "print('the f1-score is %0.3f'% score)\n",
    "\n",
    " \n",
    "mse =mean_squared_error(y1_test.values.ravel(), pred_y)\n",
    "print('Mean Squared Error: %0.3f'% mse)\n",
    "\n",
    "\n",
    "delt_for_var = pred_y - y_test\n",
    "print('Variance is %0.3f'% np.var(delt_for_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
