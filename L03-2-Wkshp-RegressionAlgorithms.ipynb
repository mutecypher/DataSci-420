{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\">Lesson 3 Basic Models</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Regression Algorithms on the Same Dataset\n",
    "\n",
    "I'm using a KFold validation on the Boston House Pricing Dataset (downloaded from Kaggle) with several regression algorithms. This dataset is designed to predict median value (continuous) based on a variety of features, including the proximity to the Charles River. \n",
    "\n",
    "Don't worry about the \"details\" for now. Just focus on the testing of the accuracy of these side by side. This is a method you can use to identify the best classifier for a particular type of problem.\n",
    "\n",
    "**Linear**\n",
    "* Linear Regression\n",
    "* Ridge Regression (L2-Norm)\n",
    "* Least Absolute Shrinkage and Selection Operator (LASSO) (L1-Norm)\n",
    "* ElasticNet (L1- and L2-Norm)\n",
    "\n",
    "**Nonlinear**\n",
    "* kNN Regressor\n",
    "* Regressor tree \n",
    "* Support Vector Regressor (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Boston Housing Data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read in the file and assign headers\n",
    "headers = ['crime', 'zone_res','zone_ind', 'C_river', 'NOX', 'rooms', 'age', 'dist', 'hwy_acc', \n",
    "         'prop_tax', 'PT_ratio', 'AA_prop', 'low_inc', 'median_val' ]\n",
    "df = pd.read_csv('https://library.startlearninglabs.uw.edu/DATASCI420/Datasets/housing.csv', \n",
    "                 delim_whitespace=True, names=headers) \n",
    "\n",
    "x1 = df.iloc[:, 0:13]   # load features into X DF\n",
    "y1 = df.iloc[:, 13]     # Load target into Y DF\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "df.plot(kind='box', subplots=True, layout=(5,3), sharex=False, sharey=False, figsize=(12,15))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algorithms for Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "Assumes the following:\n",
    "* a normal distribution\n",
    "* all of the independent variables are relevant to the dependent variable\n",
    "* the independent variables are not highly correlated with one another (no co-linearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score \n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)  # 10 fold cross validation ; \n",
    "                                            # 7 random state is to assure consistent results\n",
    "\n",
    "lin_reg_results = cross_val_score(LinearRegression(), x1, y1, cv=kfold, scoring='neg_mean_squared_error') \n",
    "print(\"Negative MAE-> mean:%.3f (std:%.3f)\" % (lin_reg_results.mean(), lin_reg_results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression\n",
    "Ridge is an extension of linear regression where the loss function is modiﬁed to minimize the complexity of the model measured as the sum squared value of the coeﬃcient values (AKA L2-norm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge \n",
    "rid_reg_results = cross_val_score(Ridge(), x1, y1, cv=kfold, scoring='neg_mean_squared_error')\n",
    "print(\"Negative MAE-> mean:%.3f (std:%.3f)\" % (rid_reg_results.mean(), rid_reg_results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO Regression (Least Absolute Shrinkage and Selection Operator)\n",
    "Modified linear regression where the loss function is modified to minimize the complexity of the model as measured by sum of the absolute vale of the coefficients (AKA L1-norm). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_results = cross_val_score(Lasso(), x1, y1, cv=kfold, scoring='neg_mean_squared_error')\n",
    "print(\"Negative MAE-> mean:%.3f (std:%.3f)\" % (lasso_results.mean(), lasso_results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet Regression\n",
    "Combines the properties of both LASSO and Ridge regressions--to minimize the complexity of a regression model--in both magnitude and regression coeficients--by penalizing the model using both L2 (sum of squared coefficient values) and L1-norm (sum absolute coefficient values). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elast_results = cross_val_score(ElasticNet(), x1, y1, cv=kfold, scoring='neg_mean_squared_error')\n",
    "print(\"Negative MAE-> mean:%.3f (std:%.3f)\" % (elast_results.mean(), elast_results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear Regression Algorithms\n",
    "### kNN Regressor\n",
    "kNN regressors use a mean or median output variable is taken as the prediction of similarity to new inputs. The distance metric used is Minkowski by default, which is a generalization of both the Euclidean distance (used when all inputs have the same scale) and Manhattan distance (used when the scales of the input variables diﬀer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "kNN_results = cross_val_score(KNeighborsRegressor(), x1, y1, cv=kfold, scoring='neg_mean_squared_error')\n",
    "print(\"Negative MAE-> mean:%.3f (std:%.3f)\" % (kNN_results.mean(), kNN_results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART\n",
    "Like the decision tree classifier except for continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "reg_tree_results = cross_val_score(DecisionTreeRegressor(), x1, y1, cv=kfold, scoring='neg_mean_squared_error')\n",
    "print(\"Negative MAE-> mean:%.3f (std:%.3f)\" % (reg_tree_results.mean(), reg_tree_results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR\n",
    "Like the Support Vector classifier except for continuous variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_results = cross_val_score(SVR(), x1, y1, cv=kfold, scoring='neg_mean_squared_error')\n",
    "print(\"Negative MAE-> mean:%.3f (std:%.3f)\" % (svr_results.mean(), svr_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LinearNeg MAE-> mean:%.3f (std:%.3f)\" % (lin_reg_results.mean(), lin_reg_results.std()))\n",
    "print(\"Ridge Neg MAE-> mean:%.3f (std:%.3f)\" % (rid_reg_results.mean(), rid_reg_results.std()))\n",
    "print(\"LASSO Neg MAE-> mean:%.3f (std:%.3f)\" % (lasso_results.mean(), lasso_results.std()))\n",
    "print(\"Elast Neg MAE-> mean:%.3f (std:%.3f)\" % (elast_results.mean(), elast_results.std()))\n",
    "print(\"kNN   Neg MAE-> mean:%.3f (std:%.3f)\" % (kNN_results.mean(), kNN_results.std()))\n",
    "print(\"CART  Neg MAE-> mean:%.3f (std:%.3f)\" % (reg_tree_results.mean(), reg_tree_results.std()))\n",
    "print(\"SVR   Neg MAE-> mean:%.3f (std:%.3f)\" % (svr_results.mean(), svr_results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this tell us?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
