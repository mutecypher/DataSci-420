Mike PearsonHere is an article titled “Accountability and reproducibility in deep learning through DeepOps”At the url. https://venturebeat.com/2019/07/10/accountability-and-reproducibility-in-deep-learning-through-deepops/The article posits a need for regulation and accountability in Deep Learning applications. The article links to some preliminary thinking on the part of the Food And Drug Administration in terms of regulating medical devices that employ machine learning, artificial intelligence, and deep learning (at url : https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-software-medical-device). Law enforcement, financial institutions and the automotive industry also see a need for regulation – who is accountable if your self-driving car injures someone: you? The car maker? The software company?The article points that web pages and mobile development have a set of best practices called DevOps. A similar thing called DeepOps is proposed with focus on 	Versioning code	Managing data	Automating computersWithout judging the specifics of the proposals, this seems like a necessary step for makers of AI/Deep Learning/Machine Learning software as their products are moved more and more into the consumer, physical world where the consequences are greater than simply approving or denying credit. So, a culture or ecosystem of responsibility, accountability, transparency, and reproducibility will need to grow up around emerging AI/Machine Learning/Deep Learning applications.