{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 9 Assignment - Wine Neural Network\n",
    "\n",
    "   ## Author - Mike Pearson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "For this assignment you will start from the perceptron neural network notebook (Simple Perceptron Neural Network.ipynb) and modify the python code to make it into a multi-layer neural network. To test your system, use the RedWhiteWine.csv file with the goal of building a red or white wine classifier. Use all the features in the dataset, allowing the network to decide how to build the internal weighting system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "1. Use the provided RedWhiteWine.csv file. Include ALL the features with “Class” being your output vector\n",
    "2. Use the provided Simple Perceptron Neural Network notebook (copied below) to develop a multi-layer feed-forward/backpropagation neural network\n",
    "4. Be able to adjust the following between experiments:\n",
    "<ul>\n",
    "<li>Learning Rate\n",
    "<li>Number of epochs\n",
    "<li>Depth of architecture—number of hidden layers between the input and output layers\n",
    "<li>Number of nodes in a hidden layer—width of the hidden layers\n",
    "<li>(optional) Momentum\n",
    "    </ul>\n",
    "5. Determine what the best neural network structure and hyperparameter settings results in the\n",
    "best predictive capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Set\n",
    "URL = \"https://library.startlearninglabs.uw.edu/DATASCI420/Datasets/RedWhiteWine.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data and set up the usual libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "wine_data = pd.read_csv(URL)\n",
    "##print(wine_data.head())\n",
    "##print(wine_data.dtypes)\n",
    "##print(wine_data.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the sigmoid function and the derivative function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid function\n",
    "\n",
    "def nonlin(x,deriv=False):\n",
    "    if(deriv==True):\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Data\n",
    " Let's scale our data and see if we can help the learning some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       fixed acidity  volatile acidity   citric acid  residual sugar  \\\n",
      "count   6.497000e+03      6.497000e+03  6.497000e+03    6.497000e+03   \n",
      "mean    5.608211e-16     -3.067277e-15  4.212037e-15   -1.136774e-16   \n",
      "std     1.071433e-01      1.097576e-01  8.754088e-02    7.297245e-02   \n",
      "min    -2.822568e-01     -1.731107e-01 -1.919477e-01   -7.428275e-02   \n",
      "25%    -6.738075e-02     -7.311067e-02 -4.134531e-02   -5.587784e-02   \n",
      "50%    -1.779397e-02     -3.311067e-02 -5.200732e-03   -3.747293e-02   \n",
      "75%     4.005727e-02      4.022267e-02  4.299204e-02    4.074792e-02   \n",
      "max     7.177432e-01      8.268893e-01  8.080523e-01    9.257172e-01   \n",
      "\n",
      "          chlorides  free sulfur dioxide  total sulfur dioxide       density  \\\n",
      "count  6.497000e+03         6.497000e+03          6.497000e+03  6.497000e+03   \n",
      "mean   1.114006e-15        -8.894056e-17         -1.392275e-16  1.260695e-13   \n",
      "std    5.819535e-02         6.162986e-02          1.302347e-01  5.781132e-02   \n",
      "min   -7.812934e-02        -1.025185e-01         -2.528677e-01 -1.462625e-01   \n",
      "25%   -2.995658e-02        -4.696291e-02         -8.927321e-02 -4.543347e-02   \n",
      "50%   -1.500641e-02        -5.296248e-03          5.196833e-03  3.727900e-03   \n",
      "75%    1.489392e-02         3.637042e-02          9.275444e-02  4.421373e-02   \n",
      "max    9.218707e-01         8.974815e-01          7.471323e-01  8.537375e-01   \n",
      "\n",
      "                 pH     sulphates       alcohol       quality  \n",
      "count  6.497000e+03  6.497000e+03  6.497000e+03  6.497000e+03  \n",
      "mean  -4.271830e-15 -1.624835e-16 -3.264986e-15 -3.017372e-16  \n",
      "std    1.246412e-01  8.359881e-02  1.728568e-01  1.455425e-01  \n",
      "min   -3.864348e-01 -1.748698e-01 -3.611306e-01 -4.697296e-01  \n",
      "25%   -8.410918e-02 -5.689229e-02 -1.437393e-01 -1.363963e-01  \n",
      "50%   -6.589804e-03 -1.194847e-02 -2.779722e-02  3.027038e-02  \n",
      "75%    7.868151e-02  3.861333e-02  1.171303e-01  3.027038e-02  \n",
      "max    6.135652e-01  8.251302e-01  6.388694e-01  5.302704e-01  \n"
     ]
    }
   ],
   "source": [
    "num_features = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides',\n",
    "                'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH',\n",
    "                'sulphates', 'alcohol', 'quality']\n",
    " \n",
    "##scaled_features = {}\n",
    "scaled_wine_data = pd.DataFrame()\n",
    "for each in num_features:\n",
    "    mean, std = wine_data[each].mean(), wine_data[each].std(), \n",
    "    rng = np.max(wine_data[each]) - np.min(wine_data[each])\n",
    "    scaled_wine_data.loc[:, each] = (wine_data[each] - mean)/rng\n",
    "\n",
    "print(scaled_wine_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a simple two layer neural network\n",
    "\n",
    "I based this code on part one of I Am Trask's tutorial (http://iamtrask.github.io/2015/07/12/basic-python-network/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape is  (6497, 12)\n",
      "y shape is  (6497, 1)\n",
      "Error after 0 iterations:0.5982139671823632\n",
      "Error after 1000 iterations:0.24613004612259184\n",
      "Error after 2000 iterations:0.246063978595473\n",
      "Error after 3000 iterations:0.24604667661406743\n",
      "Error after 4000 iterations:0.2460337236563484\n",
      "Error after 5000 iterations:0.24602300830377394\n",
      "Error after 6000 iterations:0.24601637124324072\n",
      "Error after 7000 iterations:0.246012152740657\n",
      "Error after 8000 iterations:0.24600913718284148\n",
      "Error after 9000 iterations:0.24600682221864983\n",
      "Error after 10000 iterations:0.24600500075079648\n",
      "Error after 11000 iterations:0.24600353315477785\n",
      "Error after 12000 iterations:0.24600231278641635\n",
      "Error after 13000 iterations:0.24600126569192265\n",
      "Error after 14000 iterations:0.24600034403938015\n",
      "Error after 15000 iterations:0.24599951709304807\n",
      "Error after 16000 iterations:0.24599876428171102\n",
      "Error after 17000 iterations:0.24599807109359673\n",
      "Error after 18000 iterations:0.24599742690812385\n",
      "Error after 19000 iterations:0.24599682384050872\n",
      "Output After Training:\n",
      "[[2.12444400e-151]\n",
      " [7.30056491e-139]\n",
      " [1.36091039e-099]\n",
      " [3.76258671e-043]\n",
      " [1.19487429e-130]]\n",
      "initial is  [[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "l_one shape is (6497, 2)\n",
      "l_two shape is (6497, 1)\n",
      "l_one_error shape is (6497, 2)\n",
      "l_one_delta shape is (6497, 2)\n"
     ]
    }
   ],
   "source": [
    "# input dataset - split into features (X), and results (y)\n",
    "\n",
    "Z = scaled_wine_data\n",
    "X = Z\n",
    "print(\"X shape is \", X.shape)\n",
    "\n",
    "YY = wine_data['Class'].T\n",
    "Y = YY\n",
    "y = np.array([Y]).T\n",
    "\n",
    "\n",
    "print(\"y shape is \", y.shape)\n",
    "np.random.seed(1)\n",
    "\n",
    "# initialize weights randomly with mean 0\n",
    "\n",
    "##n = hidden layers\n",
    "\n",
    "n = 2\n",
    "syn0 = 2*np.random.random((12,n)) - 1\n",
    "syn1 = 2*np.random.random((n,1)) - 1\n",
    "\n",
    "for iter in range(20000):\n",
    " \n",
    "    # forward propagation\n",
    "    l_zero = X\n",
    "    l_one = nonlin(np.dot(l_zero,syn0))\n",
    "    l_two = nonlin(np.dot(l_one, syn1))\n",
    "    # how much did we miss?\n",
    "    l_two_error = y - l_two\n",
    "    \n",
    " \n",
    "    # multiply how much we missed by the\n",
    "    # slope of the sigmoid at the values in l1\n",
    "    l_two_delta = l_two_error * nonlin(l_two,True)\n",
    "    l_one_error = l_two_delta.dot(syn1.T)\n",
    "    ##print('derivative is ', nonlin(l1,True))\n",
    "    # update weights\n",
    "    l_one_delta = l_one_error * nonlin(l_one,deriv=True)\n",
    "    if (iter% 1000) == 0:\n",
    "            print(\"Error after \"+str(iter)+\" iterations:\" + str(np.mean(np.abs(l_two_error))))\n",
    "    syn0 =syn0 + np.dot(l_zero.T,l_one_delta)\n",
    "    syn1 =syn1 + np.dot(l_one.T,l_two_delta)\n",
    "    \n",
    "\n",
    "print (\"Output After Training:\")\n",
    "print (l_two[6492:6497])\n",
    "print(\"initial is \", y[6492:6497])\n",
    "print(\"l_one shape is\", l_one.shape)  \n",
    "print(\"l_two shape is\", l_two.shape)\n",
    "print(\"l_one_error shape is\", l_one_error.shape)\n",
    "print(\"l_one_delta shape is\", l_one_delta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now with selectable alphas and selectable hidden layers\n",
    "\n",
    "I made use of the code at I am Trask (http://iamtrask.github.io/2015/07/27/python-network-part2/) for this section. I found it easier to understand than the given code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The number of epochs is  30000\n",
      "\n",
      "The number of layers is 6\n",
      "\n",
      "Training With Alpha: 0.01\n",
      "Error after 0 iterations:0.48030280948255866\n",
      "Error after 5000 iterations:0.0075764317578820095\n",
      "Error after 10000 iterations:0.005480400384825654\n",
      "Error after 15000 iterations:0.0047283704821205665\n",
      "Error after 20000 iterations:0.004250255368075119\n",
      "Error after 25000 iterations:0.003912926735376989\n",
      "Error after 30000 iterations:0.0036626100662651337\n",
      "\n",
      "Training With Alpha: 0.012\n",
      "Error after 0 iterations:0.48030280948255866\n",
      "Error after 5000 iterations:0.00681293574294505\n",
      "Error after 10000 iterations:0.0051384288262064075\n",
      "Error after 15000 iterations:0.004440341295377566\n",
      "Error after 20000 iterations:0.003984285344494108\n",
      "Error after 25000 iterations:0.0036706772554025314\n",
      "Error after 30000 iterations:0.003451855465338075\n",
      "\n",
      "Training With Alpha: 0.014\n",
      "Error after 0 iterations:0.48030280948255866\n",
      "Error after 5000 iterations:0.00633089023195261\n",
      "Error after 10000 iterations:0.004902811687083391\n",
      "Error after 15000 iterations:0.004200933503750156\n",
      "Error after 20000 iterations:0.0037639909620240768\n",
      "Error after 25000 iterations:0.0034815373569839613\n",
      "Error after 30000 iterations:0.003294138703631623\n",
      "\n",
      "Training With Alpha: 0.016\n",
      "Error after 0 iterations:0.48030280948255866\n",
      "Error after 5000 iterations:0.007690991943183091\n",
      "Error after 10000 iterations:0.005165408185304289\n",
      "Error after 15000 iterations:0.004329470379601201\n",
      "Error after 20000 iterations:0.0036034333261879517\n",
      "Error after 25000 iterations:0.0032431027041034\n",
      "Error after 30000 iterations:0.0030460756173367456\n",
      "\n",
      "The number of layers is 8\n",
      "\n",
      "Training With Alpha: 0.01\n",
      "Error after 0 iterations:0.49184814038828106\n",
      "Error after 5000 iterations:0.008584925541844769\n",
      "Error after 10000 iterations:0.005893777106060014\n",
      "Error after 15000 iterations:0.00478606139568754\n",
      "Error after 20000 iterations:0.004326825154783669\n",
      "Error after 25000 iterations:0.00385152153716359\n",
      "Error after 30000 iterations:0.0035477582413220876\n",
      "\n",
      "Training With Alpha: 0.012\n",
      "Error after 0 iterations:0.49184814038828106\n",
      "Error after 5000 iterations:0.24610528669226675\n",
      "Error after 10000 iterations:0.007993126233506212\n",
      "Error after 15000 iterations:0.00531205042256388\n",
      "Error after 20000 iterations:0.0045874107295394\n",
      "Error after 25000 iterations:0.004035746542115983\n",
      "Error after 30000 iterations:0.0038561550621246028\n",
      "\n",
      "Training With Alpha: 0.014\n",
      "Error after 0 iterations:0.49184814038828106\n",
      "Error after 5000 iterations:0.24611364762616478\n",
      "Error after 10000 iterations:0.24611335144203322\n",
      "Error after 15000 iterations:0.013365869165044087\n",
      "Error after 20000 iterations:0.006011873284483757\n",
      "Error after 25000 iterations:0.004786615995048798\n",
      "Error after 30000 iterations:0.004138287834905746\n",
      "\n",
      "Training With Alpha: 0.016\n",
      "Error after 0 iterations:0.49184814038828106\n",
      "Error after 5000 iterations:0.2461134640140842\n",
      "Error after 10000 iterations:0.24611325489012673\n",
      "Error after 15000 iterations:0.24611038606670424\n",
      "Error after 20000 iterations:0.0071681610128841436\n",
      "Error after 25000 iterations:0.0048660641529353855\n",
      "Error after 30000 iterations:0.004197091299116543\n",
      "\n",
      "The number of layers is 9\n",
      "\n",
      "Training With Alpha: 0.01\n",
      "Error after 0 iterations:0.6273609500891131\n",
      "Error after 5000 iterations:0.24611735146456412\n",
      "Error after 10000 iterations:0.24611206088221424\n",
      "Error after 15000 iterations:0.013505607714510722\n",
      "Error after 20000 iterations:0.006971681236242371\n",
      "Error after 25000 iterations:0.0053265107510280085\n",
      "Error after 30000 iterations:0.004603428888171132\n",
      "\n",
      "Training With Alpha: 0.012\n",
      "Error after 0 iterations:0.6273609500891131\n",
      "Error after 5000 iterations:0.2461137056954417\n",
      "Error after 10000 iterations:0.2461137103649028\n",
      "Error after 15000 iterations:0.24611371552888525\n",
      "Error after 20000 iterations:0.246113721276297\n",
      "Error after 25000 iterations:0.24611372771954643\n",
      "Error after 30000 iterations:0.24611373500304964\n",
      "\n",
      "Training With Alpha: 0.014\n",
      "Error after 0 iterations:0.6273609500891131\n",
      "Error after 5000 iterations:0.24611359839783892\n",
      "Error after 10000 iterations:0.24611359841726768\n",
      "Error after 15000 iterations:0.2461135984368278\n",
      "Error after 20000 iterations:0.2461135984565206\n",
      "Error after 25000 iterations:0.2461135984763477\n",
      "Error after 30000 iterations:0.24611359849631037\n",
      "\n",
      "Training With Alpha: 0.016\n",
      "Error after 0 iterations:0.6273609500891131\n",
      "Error after 5000 iterations:0.2461135914022427\n",
      "Error after 10000 iterations:0.24611359140233277\n",
      "Error after 15000 iterations:0.2461135914024229\n",
      "Error after 20000 iterations:0.24611359140251304\n",
      "Error after 25000 iterations:0.24611359140260325\n",
      "Error after 30000 iterations:0.2461135914026935\n"
     ]
    }
   ],
   "source": [
    "# Selectable hidden layers\n",
    "# Passed in the weight vectors, bias vector, the input vector and the Y\n",
    "\n",
    "n_lay = [6, 8, 9]\n",
    "alphaz = [0.01, 0.012, 0.014, 0.016]\n",
    "n_epochs = 30000\n",
    "width = 12\n",
    "\n",
    "print(\"\\nThe number of epochs is \", n_epochs)\n",
    "\n",
    "for layers in n_lay:\n",
    "    print(\"\\nThe number of layers is\", layers)\n",
    "    for alpha in alphaz:\n",
    "        np.random.seed(11)\n",
    "        ## now let's print out what alpha we are running\n",
    "        print(\"\\nTraining With Alpha:\", str(alpha))\n",
    "        ## initialize the weights of the layers\n",
    "        init_synapse = 2*np.random.random((width,layers)) - 1\n",
    "        next_synapse = 2*np.random.random((layers,1)) - 1\n",
    "    \n",
    "        for i in range(n_epochs + 1):\n",
    "            lyr_zed = X\n",
    "            lyr_one = nonlin(np.dot(lyr_zed,init_synapse))\n",
    "            lyr_two = nonlin(np.dot(lyr_one,next_synapse))\n",
    "                ## how far off?\n",
    "            lyr_two_error = y - lyr_two\n",
    "            lyr_two_delta = lyr_two_error * nonlin(lyr_two,True)\n",
    "            lyr_one_error = lyr_two_delta.dot(next_synapse.T)\n",
    "            lyr_one_delta = lyr_one_error * nonlin(lyr_one,True)\n",
    "            if (i% 5000) == 0:\n",
    "                print(\"Error after \"+str(i)+\" iterations:\" + str(np.mean(np.abs(lyr_two_error))))\n",
    "            next_synapse = next_synapse + (alpha * (lyr_one.T.dot(lyr_two_delta)))\n",
    "            init_synapse = init_synapse + (alpha * (lyr_zed.T.dot(lyr_one_delta)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best results (lowest cumulative error) looks to be with an alpha (learning rate) of 0.016, combined with 6 hidden layers, and 12 nodes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
