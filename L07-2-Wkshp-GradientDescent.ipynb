{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\">Lesson 7 Performance Metrics & Hyperparameters</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "The most common optimization algorithm used in machine learning is stochastic gradient descent.\n",
    "\n",
    "Remember that gradient descent is a cost function, used as a hyperparamter to improve your model. It is not a machine learning model.  \n",
    "\n",
    "For this lab, we'll use the [wine data set](https://canvas.uw.edu/courses/1188730/files/47572077) that we used for HW1. We'll use a linear regression model to see if we can use the wine features to predict whether or not a wine is white (0) or red (1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wine_df = pd.read_csv(\"https://library.startlearninglabs.uw.edu/DATASCI420/Datasets/RedWhiteWine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the class column has already been encoded to 0 and 1 for you\n",
    "wine_df[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "Before we can use SGD and linear regression on this data set, we must do ensure that each attribute is on the same scale. We can do this to normalizing each attribute to a range bewteen 0 and 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sklearn's preprocessing module to scale your data between 0 and 1\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform the numerical columns in your dataset\n",
    "scaled_wine = min_max_scaler.fit_transform(wine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the scaled arrays to a pandas dataframe and provide column names\n",
    "scaled_df = pd.DataFrame(scaled_wine, columns = wine_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the scaled dataframe. How does it compare to the original?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull out features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first pull out the features from the scaled dataset\n",
    "wine_features = scaled_df.drop(\"Class\", axis=1)\n",
    "wine_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now pull out the targets from the scaled_df\n",
    "wine_targets = scaled_df[\"Class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider this\n",
    "What should this targets dataframe look like? Display the first 5 rows in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into training and test sets\n",
    "Now that we've normalized our data set to be on the a scale between 0 and 1, we can split our data into training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "feature_train, feature_test = train_test_split(wine_features, test_size = 0.20)\n",
    "target_train, target_test = train_test_split(wine_targets, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Stochastic Gradient Descent (SGD)\n",
    "We can run SGD just like any other model using the following parameters: \n",
    "- loss: The loss function to be used. Defaults to ‘hinge’, which gives a linear SVM.The possible options are ‘hinge’, ‘log’, ‘modified_huber’, ‘squared_hinge’, ‘perceptron’, or a regression loss: ‘squared_loss’, ‘huber’, ‘epsilon_insensitive’, or ‘squared_epsilon_insensitive’.  \n",
    "\n",
    "- alpha: Constant that multiplies the regularization term. Defaults to 0.0001 Also used to compute learning_rate when set to ‘optimal’.  \n",
    "\n",
    "- max_iter:  number of passes over the training data \n",
    "\n",
    "- penalty: regularization term; ‘none’, ‘l2’, ‘l1’, or ‘elasticnet’. The penalty (aka regularization term) to be used. Defaults to ‘l2’ which is the standard regularizer for linear SVM models. ‘l1’ and ‘elasticnet’ might bring sparsity to the model (feature selection) not achievable with ‘l2’.\n",
    "\n",
    "See [sklearn's website](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) for additional parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model and fit the training data\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss=\"log\", penalty=\"l2\", max_iter=5 )\n",
    "clf.fit(feature_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run predictions with our testing set: \n",
    "pred = clf.predict(feature_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Model Accuracy\n",
    "Now that we have made predictions, we can use sklearn's accuracy_score method, and the target testing set we held aside to assess how accurate our model is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print (accuracy_score(pred, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Consider this\n",
    "Is our model overfit? Is that accuracy score acceptable? What else could be done to improve the accuracy?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
